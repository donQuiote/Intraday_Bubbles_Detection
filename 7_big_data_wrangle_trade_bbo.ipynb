{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling whole directories: trade and bbo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "import os\n",
    "\n",
    "dirData_raw = \"data/raw/TRTH/equities/US/\"\n",
    "dirData_clean = dirData_raw.replace(\"raw\",\"clean\")\n",
    "if not os.path.isdir(dirData_clean):\n",
    "    os.makedirs(dirData_clean)\n",
    "\n",
    "\n",
    "ticker = \"SPY.P\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column format sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0        1      2        3      4\n",
      "0    Float64  Float64  Int32  Float64  Int32\n",
      "1    Float64  Float64  Int32  Float64  Int32\n",
      "2    Float64  Float64  Int32  Float64  Int32\n",
      "3    Float64  Float64  Int32  Float64  Int32\n",
      "4    Float64  Float64  Int32  Float64  Int32\n",
      "..       ...      ...    ...      ...    ...\n",
      "565  Float64  Float64  Int32  Float64  Int32\n",
      "566  Float64  Float64  Int32  Float64  Int32\n",
      "567  Float64  Float64  Int32  Float64  Int32\n",
      "568  Float64  Float64  Int32  Float64  Int32\n",
      "569  Float64  Float64  Int32  Float64  Int32\n",
      "\n",
      "[570 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104776/2999152848.py:4: PerformanceWarning: Determining the data types of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().dtypes()` to get the data types without this warning.\n",
      "  all_dtypes = [pl.scan_parquet(myfile).dtypes for myfile in allfiles]\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "allfiles = glob.glob(dirData_raw+\"/bbo/\"+ticker+\"/*.parquet\")\n",
    "\n",
    "all_dtypes = [pl.scan_parquet(myfile).dtypes for myfile in allfiles]\n",
    "\n",
    "dtypes_DF = pd.DataFrame(all_dtypes)\n",
    "dtypes_DF = dtypes_DF.astype(str)                 # value_counts() require objects that can be ordered.\n",
    "print(dtypes_DF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now add a suffix \"-bad\" to all the files which do not have the same column dtypes as the majority.\n",
    "\n",
    "Note: some files have strings instead of floats, this is due to a problem in the original .csv file and SHOULD be corrected in a production setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "most_common_data_types = pd.DataFrame(dtypes_DF.value_counts()).iloc[0].name\n",
    "\n",
    "for idx in range(len(all_dtypes)):\n",
    "    my_dtypes=all_dtypes[idx]\n",
    "    my_dtypes=[str(x) for x in my_dtypes]\n",
    "\n",
    "    all_good = all([a==b for a,b in zip(my_dtypes,most_common_data_types)])\n",
    "    if not all_good:\n",
    "        os.rename(allfiles[idx],allfiles[idx]+\"-bad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us do it again for the trade files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104776/1748709031.py:5: PerformanceWarning: Determining the data types of a LazyFrame requires resolving its schema, which is a potentially expensive operation. Use `LazyFrame.collect_schema().dtypes()` to get the data types without this warning.\n",
      "  all_dtypes = [pl.scan_parquet(myfile).dtypes for myfile in allfiles]\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "\n",
    "allfiles = glob.glob(dirData_raw+\"/trade/\"+ticker+\"/*parquet\")\n",
    "\n",
    "all_dtypes = [pl.scan_parquet(myfile).dtypes for myfile in allfiles]\n",
    "\n",
    "dtypes_DF = pd.DataFrame(all_dtypes)\n",
    "dtypes_DF = dtypes_DF.astype(str)\n",
    "\n",
    "\n",
    "import os\n",
    "most_common_data_types = pd.DataFrame(dtypes_DF.value_counts()).iloc[0].name\n",
    "\n",
    "for idx in range(len(all_dtypes)):\n",
    "    my_dtypes=all_dtypes[idx]\n",
    "    my_dtypes=[str(x) for x in my_dtypes]\n",
    "\n",
    "    all_good = all([a==b for a,b in zip(my_dtypes,most_common_data_types)])\n",
    "    if not all_good:\n",
    "        os.rename(allfiles[idx],allfiles[idx]+\"-bad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trade and bbo wrangling functions that allow directory-wise scan_parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_trade(DF,\n",
    "            tz_exchange=\"America/New_York\",\n",
    "            only_non_special_trades=True,\n",
    "            only_regular_trading_hours=True,\n",
    "            merge_sub_trades=True):\n",
    "    excel_base_date = pl.datetime(1899, 12, 30)  # Excel starts counting from 1900-01-01, but Polars needs 1899-12-30\n",
    "    DF = DF.with_columns(\n",
    "        (pl.col(\"xltime\") * pl.duration(days=1) + excel_base_date).alias(\"index\")\n",
    "    )\n",
    "    DF = DF.with_columns(pl.col(\"index\").dt.convert_time_zone(tz_exchange))\n",
    "\n",
    "    if only_non_special_trades:\n",
    "        DF=DF.filter(pl.col(\"trade-stringflag\")==\"uncategorized\")\n",
    "\n",
    "    DF = DF.drop([\"xltime\",\"trade-rawflag\",\"trade-stringflag\"])\n",
    "\n",
    "\n",
    "    if merge_sub_trades:   # average volume-weighted trade price here\n",
    "        DF=DF.group_by('index',maintain_order=True).agg([(pl.col('trade-price')*pl.col('trade-volume')).sum()/(pl.col('trade-volume').sum()).alias('trade-price'),pl.sum('trade-volume')])        \n",
    "    \n",
    "    return DF\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_TRTH_trade_file(filename,\n",
    "            tz_exchange=\"America/New_York\",\n",
    "            only_non_special_trades=True,\n",
    "            only_regular_trading_hours=True,\n",
    "            merge_sub_trades=True):\n",
    "    try:\n",
    "        if filename.endswith(\"csv\") or filename.endswith(\"csv.gz\"):\n",
    "            DF=pl.read_csv(filename)\n",
    "        elif filename.endswith(\"parquet\"):    \n",
    "            DF=pl.read_parquet(filename)\n",
    "        else:\n",
    "            print(\"cannot load file \"+filename+\" : unknown format\")\n",
    "            return None\n",
    "    except:\n",
    "        print(filename+\" cannot be loaded\")\n",
    "        return None\n",
    "    \n",
    "    DF = wrangle_trade(DF,\n",
    "            tz_exchange=tz_exchange,\n",
    "            only_non_special_trades=only_non_special_trades,\n",
    "            only_regular_trading_hours=only_regular_trading_hours,\n",
    "            merge_sub_trades=merge_sub_trades)\n",
    "\n",
    "    return DF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_bbo(DF,\n",
    "            tz_exchange=\"America/New_York\",\n",
    "            only_regular_trading_hours=True,\n",
    "            hhmmss_open=\"09:30:00\",\n",
    "            hhmmss_close=\"16:00:00\",\n",
    "            merge_same_index=True):\n",
    "\n",
    "    excel_base_date = pl.datetime(1899, 12, 30)  # Excel starts counting from 1900-01-01, but Polars needs 1899-12-30\n",
    "    DF = DF.with_columns(\n",
    "        (pl.col(\"xltime\") * pl.duration(days=1) + excel_base_date).alias(\"index\")\n",
    "    )\n",
    "    DF = DF.with_columns(pl.col(\"index\").dt.convert_time_zone(tz_exchange))\n",
    "    DF = DF.drop(\"xltime\")\n",
    "\n",
    "    # apply common sense filter\n",
    "    DF = DF.filter(pl.col(\"ask-price\")>0).filter(pl.col(\"bid-price\")>0).filter(pl.col(\"ask-price\")>pl.col(\"bid-price\"))\n",
    "\n",
    "    if merge_same_index:\n",
    "        DF = DF.group_by('index',maintain_order=True).last()   # last quote of the same timestamp\n",
    "    \n",
    "    if only_regular_trading_hours:\n",
    "        hh_open,mm_open,ss_open = [int(x) for x in hhmmss_open.split(\":\")]\n",
    "        hh_close,mm_close,ss_close = [int(x) for x in hhmmss_close.split(\":\")]\n",
    "\n",
    "        seconds_open=hh_open*3600+mm_open*60+ss_open\n",
    "        seconds_close=hh_close*3600+mm_close*60+ss_close\n",
    "\n",
    "        DF = DF.filter(pl.col('index').dt.hour().cast(pl.Int32)*3600+pl.col('index').dt.minute().cast(pl.Int32)*60+pl.col('index').dt.second().cast(pl.Int32)>=seconds_open,\n",
    "                       pl.col('index').dt.hour().cast(pl.Int32)*3600+pl.col('index').dt.minute().cast(pl.Int32)*60+pl.col('index').dt.second().cast(pl.Int32)<=seconds_close)\n",
    "    return DF\n",
    "\n",
    "def load_TRTH_bbo_file(filename,\n",
    "            tz_exchange=\"America/New_York\",\n",
    "            only_regular_trading_hours=True,\n",
    "            hhmmss_open=\"09:30:00\",\n",
    "            hhmmss_close=\"16:00:00\",\n",
    "            merge_same_index=True):\n",
    "    try:\n",
    "        if filename.endswith(\"csv\") or filename.endswith(\"csv.gz\"):\n",
    "            DF=pl.read_csv(filename)\n",
    "        elif filename.endswith(\"parquet\"):    \n",
    "            DF=pl.read_parquet(filename)\n",
    "        else:\n",
    "            print(\"cannot load file \"+filename+\" : unknown format\")\n",
    "            return None\n",
    "    except:\n",
    "        print(filename+\" cannot be loaded\")\n",
    "        return None\n",
    "\n",
    "    DF = wrangle_bbo(DF,\n",
    "            tz_exchange=tz_exchange,\n",
    "            only_regular_trading_hours=only_regular_trading_hours,\n",
    "            hhmmss_open=hhmmss_open,\n",
    "            hhmmss_close=hhmmss_close,\n",
    "            merge_same_index=merge_same_index)\n",
    "\n",
    "    \n",
    "    return DF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>NAIVE QUERY PLAN</h4><p>run <b>LazyFrame.show_graph()</b> to see the optimized version</p><?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: polars_query Pages: 1 -->\n",
       "<svg width=\"625pt\" height=\"46pt\"\n",
       " viewBox=\"0.00 0.00 625.00 46.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 42)\">\n",
       "<title>polars_query</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-42 621,-42 621,4 -4,4\"/>\n",
       "<!-- p1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>p1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"617,-38 0,-38 0,0 617,0 617,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"308.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Parquet SCAN [data/raw/TRTH/equities/US/bbo/SPY.P/2009&#45;01&#45;02&#45;SPY.P&#45;bbo.parquet, ... 569 other sources]</text>\n",
       "<text text-anchor=\"middle\" x=\"308.5\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">π */5;</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<LazyFrame at 0x7DB9955FD720>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bbo = pl.scan_parquet(dirData_raw+\"/bbo/\"+ticker+\"/*parquet\")   # lazy loading\n",
    "df_bbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>NAIVE QUERY PLAN</h4><p>run <b>LazyFrame.show_graph()</b> to see the optimized version</p><?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: polars_query Pages: 1 -->\n",
       "<svg width=\"2072pt\" height=\"641pt\"\n",
       " viewBox=\"0.00 0.00 2072.00 641.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 637)\">\n",
       "<title>polars_query</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-637 2068,-637 2068,4 -4,4\"/>\n",
       "<!-- p1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>p1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2064,-633 0,-633 0,-597 2064,-597 2064,-633\"/>\n",
       "<text text-anchor=\"middle\" x=\"1032\" y=\"-611.3\" font-family=\"Times,serif\" font-size=\"14.00\">FILTER BY [([([([([(col(&quot;index&quot;).dt.hour().strict_cast(Int32)) * (3600)]) + ([(col(&quot;index&quot;).dt.minute().strict_cast(Int32)) * (60)])]) + (col(&quot;index&quot;).dt.second().strict_cast(Int32))]) &gt;= (34200)]) &amp; ([([([([(col(&quot;index&quot;).dt.hour().strict_cast(Int32)) * (3600)]) + ([(col(&quot;index&quot;).dt.minute().strict_cast(Int32)) * (60)])]) + (col(&quot;index&quot;).dt.second().strict_cast(Int32))]) &lt;= (57600)])]</text>\n",
       "</g>\n",
       "<!-- p2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>p2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1323,-561 741,-561 741,-508 1323,-508 1323,-561\"/>\n",
       "<text text-anchor=\"middle\" x=\"1032\" y=\"-545.8\" font-family=\"Times,serif\" font-size=\"14.00\">AGG [col(&quot;bid&#45;price&quot;).last(), col(&quot;bid&#45;volume&quot;).last(), col(&quot;ask&#45;price&quot;).last(), col(&quot;ask&#45;volume&quot;).last()]</text>\n",
       "<text text-anchor=\"middle\" x=\"1032\" y=\"-530.8\" font-family=\"Times,serif\" font-size=\"14.00\">BY</text>\n",
       "<text text-anchor=\"middle\" x=\"1032\" y=\"-515.8\" font-family=\"Times,serif\" font-size=\"14.00\">[col(&quot;index&quot;)]</text>\n",
       "</g>\n",
       "<!-- p1&#45;&#45;p2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>p1&#45;&#45;p2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1032,-596.97C1032,-586.51 1032,-572.9 1032,-561.16\"/>\n",
       "</g>\n",
       "<!-- p3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>p3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1184,-472 880,-472 880,-436 1184,-436 1184,-472\"/>\n",
       "<text text-anchor=\"middle\" x=\"1032\" y=\"-450.3\" font-family=\"Times,serif\" font-size=\"14.00\">FILTER BY [(col(&quot;ask&#45;price&quot;)) &gt; (col(&quot;bid&#45;price&quot;))]</text>\n",
       "</g>\n",
       "<!-- p2&#45;&#45;p3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>p2&#45;&#45;p3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1032,-507.8C1032,-496.17 1032,-482.74 1032,-472.33\"/>\n",
       "</g>\n",
       "<!-- p4 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>p4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1149,-400 915,-400 915,-364 1149,-364 1149,-400\"/>\n",
       "<text text-anchor=\"middle\" x=\"1032\" y=\"-378.3\" font-family=\"Times,serif\" font-size=\"14.00\">FILTER BY [(col(&quot;bid&#45;price&quot;)) &gt; (0.0)]</text>\n",
       "</g>\n",
       "<!-- p3&#45;&#45;p4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>p3&#45;&#45;p4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1032,-435.7C1032,-424.85 1032,-410.92 1032,-400.1\"/>\n",
       "</g>\n",
       "<!-- p5 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>p5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1149.5,-328 914.5,-328 914.5,-292 1149.5,-292 1149.5,-328\"/>\n",
       "<text text-anchor=\"middle\" x=\"1032\" y=\"-306.3\" font-family=\"Times,serif\" font-size=\"14.00\">FILTER BY [(col(&quot;ask&#45;price&quot;)) &gt; (0.0)]</text>\n",
       "</g>\n",
       "<!-- p4&#45;&#45;p5 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>p4&#45;&#45;p5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1032,-363.7C1032,-352.85 1032,-338.92 1032,-328.1\"/>\n",
       "</g>\n",
       "<!-- p6 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>p6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1172,-256 892,-256 892,-218 1172,-218 1172,-256\"/>\n",
       "<text text-anchor=\"middle\" x=\"1032\" y=\"-240.8\" font-family=\"Times,serif\" font-size=\"14.00\">simple π 5/6</text>\n",
       "<text text-anchor=\"middle\" x=\"1032\" y=\"-225.8\" font-family=\"Times,serif\" font-size=\"14.00\">[&quot;bid&#45;price&quot;, &quot;bid&#45;volume&quot;, ... 3 other columns]</text>\n",
       "</g>\n",
       "<!-- p5&#45;&#45;p6 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>p5&#45;&#45;p6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1032,-291.81C1032,-280.98 1032,-267.01 1032,-256.02\"/>\n",
       "</g>\n",
       "<!-- p7 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>p7</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1199.5,-182 864.5,-182 864.5,-146 1199.5,-146 1199.5,-182\"/>\n",
       "<text text-anchor=\"middle\" x=\"1032\" y=\"-160.3\" font-family=\"Times,serif\" font-size=\"14.00\">WITH COLUMNS [col(&quot;index&quot;).dt.convert_time_zone()]</text>\n",
       "</g>\n",
       "<!-- p6&#45;&#45;p7 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>p6&#45;&#45;p7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1032,-217.72C1032,-206.7 1032,-192.78 1032,-182\"/>\n",
       "</g>\n",
       "<!-- p8 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>p8</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1282,-110 782,-110 782,-74 1282,-74 1282,-110\"/>\n",
       "<text text-anchor=\"middle\" x=\"1032\" y=\"-88.3\" font-family=\"Times,serif\" font-size=\"14.00\">WITH COLUMNS [[([(col(&quot;xltime&quot;)) * (1d)]) + (1899&#45;12&#45;30 00:00:00)].alias(&quot;index&quot;)]</text>\n",
       "</g>\n",
       "<!-- p7&#45;&#45;p8 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>p7&#45;&#45;p8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1032,-145.7C1032,-134.85 1032,-120.92 1032,-110.1\"/>\n",
       "</g>\n",
       "<!-- p9 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>p9</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1340.5,-38 723.5,-38 723.5,0 1340.5,0 1340.5,-38\"/>\n",
       "<text text-anchor=\"middle\" x=\"1032\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\">Parquet SCAN [data/raw/TRTH/equities/US/bbo/SPY.P/2009&#45;01&#45;02&#45;SPY.P&#45;bbo.parquet, ... 569 other sources]</text>\n",
       "<text text-anchor=\"middle\" x=\"1032\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">π */5;</text>\n",
       "</g>\n",
       "<!-- p8&#45;&#45;p9 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>p8&#45;&#45;p9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1032,-73.81C1032,-62.98 1032,-49.01 1032,-38.02\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<LazyFrame at 0x7DB969F1DE40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bbo = wrangle_bbo(df_bbo)\n",
    "df_bbo   # computation graph completed with that of wrangle_bbo (nothing has been computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(dirData_clean+\"/bbo\"):\n",
    "    os.makedirs(dirData_clean+\"/bbo\")\n",
    "    \n",
    "df_bbo.collect(streaming=True).write_parquet(dirData_raw+\"/bbo/\"+ticker+\".parquet\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trade = pl.scan_parquet(dirData_raw+\"/trade/SPY.P/*parquet\")\n",
    "df_trade = wrangle_trade(df_trade)\n",
    "\n",
    "if not os.path.isdir(dirData_clean+\"/trade\"):\n",
    "    os.makedirs(dirData_clean+\"/trade\")\n",
    "\n",
    "df_trade.collect(streaming=True).write_parquet(dirData_clean+\"/trade/\"+ticker+\"_trade.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FBD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
